{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16ca4650",
   "metadata": {},
   "source": [
    "# Exoplanet Data Analysis\n",
    "## Python Workbook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b08dc",
   "metadata": {},
   "source": [
    "#### Firstly, import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b011a99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as axes\n",
    "import matplotlib.colors as mccolours\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.transforms import Bbox\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.collections as collections\n",
    "import matplotlib.lines as lines\n",
    "from pandas import read_csv\n",
    "from pandas import Series\n",
    "from astropy import coordinates\n",
    "from astropy import units\n",
    "from astropy.table import QTable, vstack, Column, hstack\n",
    "from astroquery.simbad import Simbad\n",
    "from astroquery import gaia as Gaia\n",
    "from astroquery.gaia import GaiaClass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59ef790",
   "metadata": {},
   "source": [
    "## Graph Plotting Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd5528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(filename, headerRow=290):\n",
    "    '''\n",
    "    Read csv data.\n",
    "    '''\n",
    "    return read_csv(filename, header=headerRow)\n",
    "\n",
    "def plotScatterGraphOfData(szTitle, xAxis, yAxis, xData, yData, xError, yError, logariseXAxis, logariseYAxis, colours = np.array([]), colourAxisLabel = \"\", bColourLoggersised=False, sizes = np.array([]), tickSeperation = 0.5):\n",
    "    bWasColourData = False\n",
    "\n",
    "    plt.rcParams['font.family'] = \"Times New Roman\"\n",
    "    plt.rcParams['font.size'] = 10\n",
    "    plt.rcParams['axes.labelsize'] = 10 # 10  # Size of axis labels\n",
    "    plt.rcParams['axes.titlesize'] = 10  # Size of title\n",
    "    plt.rcParams['xtick.labelsize'] = 10 # 8  # Size of x-axis tick labels\n",
    "    plt.rcParams['ytick.labelsize'] = 10 # 8  # Size of y-axis tick labels\n",
    "    plt.rcParams['legend.fontsize'] = 10 # 8  # Size of legend font\n",
    "    plt.rcParams['figure.figsize'] = [3.5, 2.5] # [3.487, 2.155]  # Figure dimension in inches (1-column width)\n",
    "    plt.rcParams['figure.dpi'] = 300  # Figure resolution\n",
    "    plt.rcParams['savefig.dpi'] = 300  # Resolution of saved figure\n",
    "    plt.rcParams['text.usetex'] = True  # Use LaTeX for text rendering\n",
    "\n",
    "    # Sets the colours of the data points if no colour data was specified\n",
    "    if colours.size == 0:\n",
    "        colours = np.full(shape=xData.size , fill_value=\"b\")\n",
    "    else:\n",
    "        bWasColourData = True\n",
    "    \n",
    "    # Creates the colour map\n",
    "    if (bColourLoggersised and bWasColourData):\n",
    "        myNorm = LogNorm(vmin=colours.min(), vmax=colours.max())\n",
    "        colourMap = cm.ScalarMappable(norm=myNorm, cmap=\"Spectral\")\n",
    "    else:\n",
    "        myNorm = None\n",
    "        colourMap = cm.ScalarMappable(cmap=\"Spectral\")\n",
    "    \n",
    "    colourMap.set_array(colours)\n",
    "\n",
    "    # Extracts the array of colours from the colour map\n",
    "    rgbaArray = cm.ScalarMappable.to_rgba(colourMap, colourMap.get_array())\n",
    "\n",
    "    # Sets the sizes of the data points if no size data was specified\n",
    "    if sizes.size == 0:\n",
    "        sizes = np.full(shape=xData.size , fill_value=6)\n",
    "\n",
    "    # Create the figure and get the main axes\n",
    "    figure = plt.figure(dpi=400)\n",
    "    mainAxes = figure.gca()\n",
    "\n",
    "    # Sets the aspect ratio of the atual graph (not including the error bar)\n",
    "    mainAxes.set_box_aspect(1.0)\n",
    "\n",
    "    # Create the scatter graph onto the main axes\n",
    "    mainAxes.scatter(xData, yData, s = sizes, c = rgbaArray, cmap = colourMap, marker=\"o\")\n",
    "\n",
    "    # Adds error bars\n",
    "    if bWasColourData == True:\n",
    "        # Creates error bars and extracts their details\n",
    "        dataLines, capLines, barLines = mainAxes.errorbar(xData, yData, xerr=xError, yerr=yError, fmt=\"none\", elinewidth=0.6, capsize=0, barsabove=True, capthick=0.5)\n",
    "\n",
    "        # Set's the colour of the error bars\n",
    "        barLines[0].set_colors(rgbaArray) # Does the x lines\n",
    "        barLines[1].set_colors(rgbaArray) # Does the y lines\n",
    "        \n",
    "        # Unfortunetly the below code does not do anything. You may try. Due to this we cannot have coloured caps, so we choose to not include them\n",
    "        #  capLines[0].set_color((rgbaArray, rgbaArray))\n",
    "        #  capLines[1].set_color((rgbaArray, rgbaArray))\n",
    "\n",
    "    else:\n",
    "        mainAxes.errorbar(xData, yData, xerr=xError, yerr=yError, fmt=\"none\", ecolor='black', elinewidth=0.6, capsize=0, barsabove=True, capthick=0.5)\n",
    "\n",
    "    # Adds a title\n",
    "    mainAxes.set_title(szTitle)\n",
    "\n",
    "    # Customise the axes\n",
    "    if logariseXAxis:\n",
    "        mainAxes.set_xscale(\"log\")\n",
    "    if logariseYAxis:\n",
    "        mainAxes.set_yscale(\"log\")\n",
    "    mainAxes.set_xlabel(xAxis)\n",
    "    mainAxes.set_ylabel(yAxis)\n",
    "\n",
    "    mainAxes.xaxis.set_major_locator(ticker.MultipleLocator(tickSeperation))\n",
    "    mainAxes.xaxis.set_minor_locator(ticker.MultipleLocator(tickSeperation/5.0))\n",
    "\n",
    "    mainAxes.tick_params(axis='both', which = 'both', direction='in', top = True, right = True)\n",
    "    mainAxes.tick_params(axis='both', which = 'major', length = 2, width = 0.5)\n",
    "    mainAxes.tick_params(axis='both', which = 'minor', length = 1, width = 0.5)\n",
    "\n",
    "    # Creates the colour bar\n",
    "    if bWasColourData:\n",
    "        colourBarAxes = figure.add_axes((0.85, 0.12, 0.05, 0.75))\n",
    "        figure.colorbar(colourMap, cax=colourBarAxes)\n",
    "        colourBarAxes.set_ylabel(colourAxisLabel)\n",
    "        if (bColourLoggersised):\n",
    "            colourBarAxes.set_yscale(\"log\")\n",
    "\n",
    "        colourBarAxes.tick_params(axis='both', which = 'major', length = 2, width = 0.5)\n",
    "        colourBarAxes.tick_params(axis='both', which = 'minor', length = 1, width = 0.5)\n",
    "\n",
    "    # Returns the entire figure\n",
    "    return figure\n",
    "\n",
    "# Saves the graph in the specified format. We recommend \"pdf\". This ensures that no quality is lossed,\n",
    "# compatibility is maximised, text can be highlighted and copied etc., and file size is minimal\n",
    "def saveGraph(saveFileName, szFormat=\"pdf\"):\n",
    "        plt.savefig(saveFileName, format=szFormat)\n",
    "        print(\"Graph saved as a\", szFormat, \"file with name:\", saveFileName)\n",
    "\n",
    "\n",
    "# Create a colour dictionary of detection methods from the exoplanet archive data\n",
    "def detectionMethodColourDictionary(planetData):\n",
    "    detectionMethods = planetData[\"discoverymethod\"].to_numpy()\n",
    "    detectionColours = detectionMethods.copy()\n",
    "    i = 0\n",
    "    for detectionMethod in detectionMethods:\n",
    "        if detectionMethod == \"Radial Velocity\":\n",
    "            detectionColours[i] = \"r\"\n",
    "        elif detectionMethod == \"Transit\":\n",
    "            detectionColours[i] = \"b\"\n",
    "        elif detectionMethod == \"Imaging\":\n",
    "            detectionColours[i] = \"g\"\n",
    "        else:\n",
    "            detectionColours[i] = \"m\"\n",
    "        i = i + 1\n",
    "    \n",
    "    return detectionColours\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd00750",
   "metadata": {},
   "source": [
    "## Data Analysis Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef585d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGAIAData(coordsAndMagnitudes):\n",
    "    \"Retrives data on a single GAIA object\"\n",
    "\n",
    "    # Put the coordinates into a skycoord object\n",
    "    mySkyCoords = coordinates.SkyCoord(ra=coordsAndMagnitudes[\"Right Ascension\"], dec=coordsAndMagnitudes[\"Declination\"])\n",
    "\n",
    "    # Search for the system in the GAIA archive\n",
    "    print(\"Querying the GAIA archive\")\n",
    "    myStarProperties = Gaia.Gaia.query_object_async(mySkyCoords, width=8*units.arcsecond, height=8*units.arcsecond)\n",
    "\n",
    "    # Further filter using magnitudes\n",
    "    myStarProperties = myStarProperties[myStarProperties['phot_g_mean_mag'] > (coordsAndMagnitudes[\"GAIA Magnitude\"] - 0.5)]\n",
    "    myStarProperties = myStarProperties[myStarProperties['phot_g_mean_mag'] < (coordsAndMagnitudes[\"GAIA Magnitude\"] + 0.5)]\n",
    "\n",
    "    # parallaxErrorMyStar = myStarProperties['parallax_error']\n",
    "    return myStarProperties\n",
    "\n",
    "def getGAIADataMultipleStars2(coordsAndMagnitudes, width = 8, height = 8):\n",
    "    \"Returns an AstroPy QTable for a list of all objects matching those in the list of objects passed to this function\"\n",
    "    return(getGAIADataMultipleStars(coordsAndMagnitudes['Right Ascension'], coordsAndMagnitudes['Declination'], coordsAndMagnitudes['GAIA Magnitude'], width, height))\n",
    "\n",
    "\n",
    "def getGAIADataMultipleStars(RAs, Decs, gaiaMagnitudes, width = 8, height = 8):\n",
    "    \"Returns an AstroPy QTable for a list of all objects matching those in the list of objects passed to this function\"\n",
    "    # Defines the width of the box to search\n",
    "    width=width*units.arcsecond\n",
    "    height=height*units.arcsecond\n",
    "\n",
    "    # If the code breaks at this line, please post an issue on the github page (https://github.com/george112n/How-Metallicity-Affects-Exoplanets/issues/new)\n",
    "    \n",
    "    # Define the table names of the GAIA archive - Up to date on 13/03/24. As seen DR3 is the latest release on this date.\n",
    "    gaiaSourceTable = \"gaiadr3.gaia_source\"\n",
    "    gaiaAstrophysicalParametersTable = \"gaiadr3.astrophysical_parameters\"\n",
    "\n",
    "    # Defines the list of coloumns that you are interested in from the gaiaSourceTable\n",
    "    columns = \"{gaiaSourceTable}.ra, {gaiaSourceTable}.ra_error, {gaiaSourceTable}.dec, {gaiaSourceTable}.dec_error, {gaiaSourceTable}.pmra, {gaiaSourceTable}.pmra_error, {gaiaSourceTable}.pmdec, {gaiaSourceTable}.pmdec_error, {gaiaSourceTable}.radial_velocity, {gaiaSourceTable}.radial_velocity_error, {gaiaSourceTable}.parallax, {gaiaSourceTable}.parallax_error, {gaiaSourceTable}.phot_g_mean_mag\"\n",
    "    \n",
    "    # Defines the list of coloumns that you are interested in from the AstroPhysicalParams\n",
    "    columns = columns + \", {AstroPhysicalParams}.mh_gspphot, {AstroPhysicalParams}.mh_gspphot_upper, {AstroPhysicalParams}.mh_gspphot_lower, {AstroPhysicalParams}.alphafe_gspspec, {AstroPhysicalParams}.alphafe_gspspec_lower, {AstroPhysicalParams}.alphafe_gspspec_upper\"\n",
    "    \n",
    "    # Substitutes the placeholder for the table names with the real table names\n",
    "    columns = columns.format(**{'gaiaSourceTable': gaiaSourceTable, 'AstroPhysicalParams': gaiaAstrophysicalParametersTable})\n",
    "    \n",
    "    ### The following lines of code create a single query for all of the objects you are interested in ###\n",
    "    query = \"\"\"\n",
    "        SELECT\n",
    "        {row_limit}\"\"\" #   DISTANCE(\n",
    "        #     POINT('ICRS', {ra_column}, {dec_column}),\n",
    "        #     POINT('ICRS', {ra}, {dec})\n",
    "        # ) as dist,\"\"\"\n",
    "    query = query + \"\"\"\n",
    "        {columns}\n",
    "        FROM\n",
    "        {gaiaSourceTable}\n",
    "        JOIN {AstroPhysicalParams} ON {AstroPhysicalParams}.source_id = {gaiaSourceTable}.source_id\n",
    "        WHERE \"\"\"\n",
    "    for i in range(len(RAs) - 1):\n",
    "        query = query + \"\"\"(1 = CONTAINS(\n",
    "            POINT('ICRS', {gaiaSourceTable}.{ra_column}, {gaiaSourceTable}.{dec_column}),\n",
    "            BOX('ICRS',\n",
    "                \"\"\"\n",
    "        query = query + str(RAs[i].value) + \", \"\n",
    "        query = query + str(Decs[i].value) + \"\"\",\n",
    "            {width},\n",
    "            {height}\n",
    "                )\n",
    "            )\n",
    "            AND ({gaiaSourceTable}.phot_g_mean_mag BETWEEN \"\"\" +str(gaiaMagnitudes[i]-0.5) +\" AND \" +str(gaiaMagnitudes[i]+0.5) +\"\"\")\n",
    "        )\n",
    "        OR\n",
    "        \"\"\"\n",
    "    \n",
    "    query = query + \"\"\"(1 = CONTAINS(\n",
    "        POINT('ICRS', {gaiaSourceTable}.{ra_column}, {gaiaSourceTable}.{dec_column}),\n",
    "        BOX('ICRS',\n",
    "            \"\"\"\n",
    "    query = query + str(RAs[len(RAs) - 1].value) + \", \"\n",
    "    query = query + str(Decs[len(RAs) - 1].value) + \"\"\",\n",
    "        {width},\n",
    "        {height}\n",
    "        )\n",
    "    )\n",
    "    AND({gaiaSourceTable}.phot_g_mean_mag BETWEEN \"\"\" +str(gaiaMagnitudes[len(RAs) - 1]-0.5) +\" AND \" +str(gaiaMagnitudes[len(RAs) - 1]+0.5) +\"\"\")\n",
    "    )\"\"\"\n",
    "\n",
    "    query = query.format(**{'row_limit': \"\",\n",
    "                      'ra_column': GaiaClass.MAIN_GAIA_TABLE_RA, 'dec_column': GaiaClass.MAIN_GAIA_TABLE_DEC,\n",
    "                      'columns': \"*\" if columns == \"\" else columns,\n",
    "                      'table_name': gaiaSourceTable+\",\"+gaiaAstrophysicalParametersTable,\n",
    "                      'gaiaSourceTable': gaiaSourceTable, 'AstroPhysicalParams': gaiaAstrophysicalParametersTable,\n",
    "                      'width': width.to(units.deg).value , 'height': height.to(units.deg).value})\n",
    "    \n",
    "    # print(query)\n",
    "\n",
    "    # Queries the GAIA archive\n",
    "    print(\"Querying the GAIA archive\")\n",
    "    job = Gaia.Gaia.launch_job_async(query, verbose=True)\n",
    "    \n",
    "    # Use job. to retrieve more information about the GAIA job\n",
    "\n",
    "    # Returns the job results\n",
    "    return(job.get_results())\n",
    "\n",
    "def getAllGAIAObjects():\n",
    "    \"\"\"Queries the top 10000 GAIA objects from the gaia_source table\\n\n",
    "    Use this for testing your connection to the GAIA archive\"\"\"\n",
    "    \n",
    "    print(\"Querying the GAIA archive\")\n",
    "    job = Gaia.Gaia.launch_job_async(\"select top 10000 ra, ra_error, dec, dec_error, pmra, pmra_error, pmdec, pmdec_error, radial_velocity, radial_velocity_error, parallax, parallax_error, mh_gspphot, mh_gspphot_upper, mh_gspphot_lower from gaiadr3.gaia_source\")\n",
    "    return(job.get_results())\n",
    "\n",
    "def computeGalacticVelocity(GAIAStar):\n",
    "    \"Calculates the galatic velocity of a star given a row of an AstroPy table retrieved from the GAIA Exoplanet archive\"\n",
    "    # Extract some star data from the GAIA archive results\n",
    "    rightAscension = GAIAStar['ra']\n",
    "    rightAscensionError = GAIAStar['ra_error']\n",
    "\n",
    "    declenation = GAIAStar['dec']\n",
    "    declenationError = GAIAStar['dec_error']\n",
    "\n",
    "    properMotionRA = GAIAStar['pmra']\n",
    "    properMotionRAError = GAIAStar['pmra_error']\n",
    "\n",
    "    properMotionDec = GAIAStar['pmdec']\n",
    "    properMotionDecError = GAIAStar['pmdec_error']\n",
    "\n",
    "    radialVelocity = GAIAStar['radial_velocity']\n",
    "    radialVelocityErr = GAIAStar['radial_velocity_error']\n",
    "\n",
    "    # And the paralax\n",
    "    parallax = GAIAStar['parallax']\n",
    "    parallaxError = GAIAStar['parallax_error']\n",
    "\n",
    "    return(GalaVel(rightAscension, declenation, properMotionRA, properMotionRAError, properMotionDec, properMotionDecError, radialVelocity, radialVelocityErr, parallax, parallaxError))\n",
    "\n",
    "# This function was entirely provided by Thomas Wilson\n",
    "def GalaVel(RA, Dec, muRA, sigmuRA, muDec, sigmuDec, radv, sigradv, para, sigpara):\n",
    "     # Using Formulae from Johnson and SoderBlom 1987\n",
    "     # Updated values of NGP to fit into the ICRS\n",
    "\n",
    "     # Takes astrometric parameters in ICRS j2000 and returns the heliocentric velocities in the galactic coordinates,\n",
    "     # in a right handed (wrt the rotation) sense. Parameters are\n",
    "     #  RA/Dec: RA/Dec of the object, in decimal degrees\n",
    "     #  para,sigpara: Parallax and the associated uncertainty, in arcsec\n",
    "     #  radv,sigradv: Radial Velocity and the associated uncertainty,in km/s\n",
    "     #  muRA/muDec,sigmuRA/sigmuDec: Proper motion in RA/Dec and the associated uncertainty, in arcsec/yr.\n",
    "\n",
    "     # The ICRS from the GAIA documentation (DR3 Section 4.1.7 \"Transformations of astrometric data and error propagation\")\n",
    "     alphaNGP = 192.85948 * np.pi / 180.0  # radians, because trig functions use those, not degrees\n",
    "     deltaNGP = 27.12825 * np.pi / 180.0\n",
    "     theta0 = (90 + 32.93192) * np.pi / 180.0  # The angle in J&S is \"Galactic RA\", for lack of a better term.\n",
    "\n",
    "     # RA,Dec in radians\n",
    "     RA = RA * np.pi / 180.0\n",
    "     Dec = Dec * np.pi / 180.0\n",
    "\n",
    "     # Matrix T from paper\n",
    "     T1 = np.array([[np.cos(theta0), np.sin(theta0), 0],\n",
    "                    [np.sin(theta0), -np.cos(theta0), 0],\n",
    "                    [0, 0, 1]])\n",
    "     T2 = np.array([[-np.sin(deltaNGP), 0, np.cos(deltaNGP)],\n",
    "                    [0, -1, 0],\n",
    "                    [np.cos(deltaNGP), 0, np.sin(deltaNGP)]])\n",
    "     T3 = np.array([[np.cos(alphaNGP), np.sin(alphaNGP), 0],\n",
    "                    [np.sin(alphaNGP), -np.cos(alphaNGP), 0],\n",
    "                    [0, 0, 1]])\n",
    "     T = T1 @ (T2 @ T3)\n",
    "\n",
    "     # Matrix A from paper\n",
    "     A = [[np.cos(RA) * np.cos(Dec), -np.sin(RA), -np.cos(RA) * np.sin(Dec)],\n",
    "          [np.sin(RA) * np.cos(Dec), np.cos(RA), -np.sin(RA) * np.sin(Dec)],\n",
    "          [np.sin(Dec), 0, np.cos(Dec)]]\n",
    "\n",
    "     # Give Velocities in a vector\n",
    "     k = 4.740470464\n",
    "     B = (T @ A)\n",
    "     Vels = B @ np.array([radv, k * muRA / para, k * muDec / para])\n",
    "\n",
    "     # Uncertainties\n",
    "     C = B ** 2\n",
    "     term1 = C @ np.array([sigradv ** 2,\n",
    "                           (k / para) ** 2 * (sigmuRA ** 2 + (muRA * sigpara / para) ** 2),\n",
    "                           (k / para) ** 2 * (sigmuDec ** 2 + (muDec * sigpara / para) ** 2)])\n",
    "     term2 = (2 * muRA * muDec * (k ** 2) * (sigpara ** 2) / para ** 4) * np.array([B[0, 1] * B[0, 2], B[1, 1] * B[1, 2], B[2, 1] * B[2, 2]])\n",
    "\n",
    "     sigVels = np.sqrt(term1 + term2)\n",
    "\n",
    "     return (np.array([Vels, sigVels]).T).flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b192e8",
   "metadata": {},
   "source": [
    "## Statistical Analysis\n",
    "This code was originally written by Figueira et al. (2016) to compliment a Bayesian correlation analysis technique they had designed\n",
    "\n",
    "They describe he technique in this paper: https://doi.org/10.1007/s11084-016-9490-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca699127",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Written by Pedro Figueira. \n",
    "Original version can be found at https://pedrofigueira@bitbucket.org/pedrofigueira/bayesiancorrelation\n",
    "See https://doi.org/10.1007/s11084-016-9490-5 for a description of this method\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Modified by Thomas Wilson in 2024\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Modified by George in 2024\n",
    "The most up to date version may be found on https://github.com/george112n/How-Metallicity-Affects-Exoplanets\n",
    "See the 'releases' for static and numbered versions\n",
    "\"\"\"\n",
    "\n",
    "# import string, sys\n",
    "from numpy import average, std, array, sqrt\n",
    "\n",
    "from scipy.stats import rankdata, chi2, norm\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# from pylab import hist, show\n",
    "\n",
    "from arviz import hdi\n",
    "\n",
    "def MCMC_model(x_input, y_input, spearmanrank=False, analytical=True):\n",
    "    \"\"\"\n",
    "    MCMC calculation for the BiVariate Normal distribution assumed\n",
    "        parameters:\n",
    "        inputfile: x,y tab-separated file with the data\n",
    "                    -- or --\n",
    "                   [] for test running (default)\n",
    "        spearmanrank: flag to toggle pearsonr calculation (False, set by \n",
    "                        default) or spearman's rank (True)\n",
    "        save_posterior: flag to save the posterior distribution ASCII one-column file.\n",
    "        analytical: flag to perform an analytical calculation of the posterior \n",
    "    \"\"\"    \n",
    "        \n",
    "    # if(inputfile==[]):\n",
    "    #     # print (\"Reading test data.\")\n",
    "    #     # #example from http://sumsar.net/blog/2014/03/bayesian-first-aid-pearson-correlation-test/\n",
    "    #     # x_input, y_input = np.loadtxt(\"testdata_male.txt\", unpack=True)\n",
    "    # else:\n",
    "    #     x_input, y_input = np.loadtxt(inputfile, unpack=True)\n",
    "        \n",
    "    \n",
    "    # x_input = np.array(x_input)\n",
    "    # y_input = np.array(y_input)\n",
    "\n",
    "    pearsonRAnalysis = pearsonr(x_input, y_input)\n",
    "\n",
    "    # print(\"The pearson's coefficient of the data is %.3f with a %.3f 2-sided p-value \" % (pearsonRAnalysis[0], pearsonRAnalysis[1]))\n",
    "    # print(\"The spearman's rank coefficient of the data is %.3f with a %.3f 2-sided p-value \" % (spearmanr(x_input, y_input)[0], spearmanr(x_input, y_input)[1]))\n",
    "    \n",
    "    # print(\"Ranking data\")\n",
    "\n",
    "    if(spearmanrank):\n",
    "        #rank variable for spearman's rank calculation\n",
    "        x_input = rankdata(x_input)\n",
    "        y_input = rankdata(y_input)\n",
    "    \n",
    "            \n",
    "    if(analytical):\n",
    "        # print(\"\\n\"*2)\n",
    "        # print(\"-\" * 66) \n",
    "        # print(\"Performing analytical calculation...\")\n",
    "        rho_post = calculate_posterior(pearsonRAnalysis[0], len(x_input))\n",
    "        hdiResults = hdi(rho_post[:], hdi_prob=0.95)\n",
    "        parameters = array([average(rho_post), std(rho_post), hdiResults[0], hdiResults[1]])\n",
    "        # print(\"The mean, std and 95%% HPD are %.3f, %.3f, and [%.3f, %.3f].\" % (np.average(rho_post), np.std(rho_post), pm.utils.hpd(rho_post[:], 1.0-0.95)[0], pm.utils.hpd(rho_post[:], 1.0-0.95)[1]))\n",
    "        # print(\"The mean, std and 95%% HPD are %.3f, %.3f, and [%.3f, %.3f].\" % (parameters[0], parameters[1], parameters[2], parameters[3]))\n",
    "        # print(\"The mean over the std (mean/std) is %.3f\" % (parameters[0]/parameters[1]))\n",
    "        # print (\"-\" * 66)\n",
    "        # print(\"\\n\"*2) \n",
    "\n",
    "    # When iterating over a continuum of different ranges this part consumes a lot of time due to file opening. I do not believe it works either.\n",
    "        \n",
    "    # with open('rho_summary.csv','w') as file:\n",
    "    #     file.write('mean,std,2sigma_low_err,2sigma_up_err,3sigma_low_err,3sigma_up_err\\n')\n",
    "    #     file.write(str(parameters[0])+','+str(parameters[1])+','+str(parameters[0]-parameters[2])+','+str(parameters[3]-parameters[0])+','+str(parameters[0]-az.hdi(rho_post[:], hdi_prob=0.997)[0])+','+str(az.hdi(rho_post[:], hdi_prob=0.997)[1]-parameters[0]))\n",
    "    \n",
    "    # Returns some statistics of the distribution and some \n",
    "    return parameters, rho_post \n",
    "\n",
    "def calculate_posterior(r, n, a=1, b=2, N=10000):\n",
    "    # function for Analytical posterior calculation\n",
    "\n",
    "    Z = norm.rvs(size=N)\n",
    "    chi2_1 = chi2.rvs(n-a, size=N)\n",
    "    chi2_2 = chi2.rvs(n-b, size=N)\n",
    "    \n",
    "    sqrtchi2_1 = sqrt(chi2_1)\n",
    "\n",
    "    Y = - Z/sqrtchi2_1 + (sqrt(chi2_2) / sqrtchi2_1) * (r / sqrt(1-r**2))\n",
    "    rho_post = Y / sqrt(1+Y**2.0)\n",
    "    return rho_post\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e231a1f",
   "metadata": {},
   "source": [
    "## Input analysis parametres here\n",
    "Set up the variables here, including file name, and plot data and axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaaf84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determines whether the file name is to take user input or take the hard coded value\n",
    "bCustomFileName = False\n",
    "szFileName = \"PS_2024.02.19_11.15.47.csv\" # Only use if above is set to false\n",
    "\n",
    "szGraphTitle = \"\"\n",
    "\n",
    "#The file name of the graph. Must end in .svg\n",
    "saveFileName = \"Planet Density-Stellar Metallicity.png\"\n",
    "\n",
    "if bCustomFileName:\n",
    "    # Accepts user input of the file name\n",
    "    szFileName = input(\"Input the file name of the exoplanet data: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1930a3c",
   "metadata": {},
   "source": [
    "## Reads exoplanet data from file\n",
    "Omits controversial data and rows which are not the default parameters for the given planet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac88215",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading exoplanet data from file '\", szFileName, \"'\")\n",
    "\n",
    "# Reads the exoplanet data from the file\n",
    "allData = readData(szFileName)\n",
    "\n",
    "# Omit data with a Controversial flag (pl_controv_flag)\n",
    "allNonControversialData = allData[allData['pl_controv_flag'] == 0]\n",
    "\n",
    "# Confrain the planets to planets with the default_flag (Avoids repeated plotting) (default_flag)\n",
    "allNonControversialAndDefaultData = allNonControversialData[allNonControversialData['default_flag'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded69a4f",
   "metadata": {},
   "source": [
    "## Analysing planet properties againt their host star properties\n",
    "### Compiling the list of planets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5e753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# --------------------- Planet property quality cuts ---------------------\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# Perform planet property quality cuts before GAIA query in order to reduce the amount of network data\n",
    "allGoodExoplanets = allNonControversialData[allNonControversialData['default_flag'] == 1]\n",
    "\n",
    "# Quality cut with the insolation data\n",
    "allGoodExoplanets = allGoodExoplanets[allGoodExoplanets['pl_insollim'] == 0]\n",
    "allGoodExoplanets = allGoodExoplanets[allGoodExoplanets['pl_insolerr1']/allGoodExoplanets['pl_insol'] < 0.2]\n",
    "allGoodExoplanets = allGoodExoplanets[(allGoodExoplanets['pl_insolerr2']*-1)/allGoodExoplanets['pl_insol'] < 0.2]\n",
    "\n",
    "# Only accept planets with a defined density\n",
    "# allGoodExoplanets = allGoodExoplanets[allGoodExoplanets['pl_denslim'] != 1]\n",
    "# allGoodExoplanets = allGoodExoplanets[allGoodExoplanets['pl_denserr1']/allGoodExoplanets['pl_dens'] < 0.2]\n",
    "# allGoodExoplanets = allGoodExoplanets[(allGoodExoplanets['pl_denserr2']*-1)/allGoodExoplanets['pl_dens'] < 0.2]\n",
    "\n",
    "# Quality cut with the mass data\n",
    "allGoodExoplanets = allGoodExoplanets[allGoodExoplanets['pl_masselim'] == 0]\n",
    "allGoodExoplanets = allGoodExoplanets[allGoodExoplanets['pl_masseerr1']/allGoodExoplanets['pl_masse'] < 0.2]\n",
    "allGoodExoplanets = allGoodExoplanets[(allGoodExoplanets['pl_masseerr2']*-1)/allGoodExoplanets['pl_masse'] < 0.2]\n",
    "\n",
    "# Add the colour dimension (for fun)\n",
    "# allGoodExoplanets = allGoodExoplanets[allGoodExoplanets['pl_insol'] > -1]\n",
    "\n",
    "# ---------- Radii ---------- #\n",
    "allGoodExoplanets = allGoodExoplanets[allGoodExoplanets['pl_radelim'] == 0]\n",
    "allGoodExoplanets = allGoodExoplanets[allGoodExoplanets['pl_radeerr1']/allGoodExoplanets['pl_rade'] < 0.2]\n",
    "allGoodExoplanets = allGoodExoplanets[(allGoodExoplanets['pl_radeerr2']*-1)/allGoodExoplanets['pl_rade'] < 0.2]\n",
    "\n",
    "#print(allGoodExoplanets)\n",
    "# print(allGoodExoplanets.to_string())\n",
    "\n",
    "# Extract the coordinates and gaia magnitudes of all of the NASA exoplanet hosting stars\n",
    "\n",
    "# Create astropy table from NASA data of exoplanet hosting stars\n",
    "allGoodExoplanetsTable = QTable()\n",
    "allGoodExoplanetsTable['Density'] = allGoodExoplanets['pl_dens'].to_numpy() * (units.g/(units.cm)**3)\n",
    "allGoodExoplanetsTable['Density Error Up'] = allGoodExoplanets['pl_denserr1'].to_numpy() * (units.g/(units.cm)**3)\n",
    "allGoodExoplanetsTable['Density Error Down'] = allGoodExoplanets['pl_denserr2'].to_numpy() * (units.g/(units.cm)**3)\n",
    "allGoodExoplanetsTable['Mass (Earth)'] = allGoodExoplanets['pl_masse'].to_numpy()\n",
    "allGoodExoplanetsTable['Mass (Earth) Error Up'] = allGoodExoplanets['pl_masseerr1'].to_numpy()\n",
    "allGoodExoplanetsTable['Mass (Earth) Error Down'] = allGoodExoplanets['pl_masseerr2'].to_numpy()\n",
    "allGoodExoplanetsTable['Radius (Earth)'] = allGoodExoplanets['pl_rade'].to_numpy()\n",
    "allGoodExoplanetsTable['Radius (Earth) Error Up'] = allGoodExoplanets['pl_radeerr1'].to_numpy()\n",
    "allGoodExoplanetsTable['Radius (Earth) Error Down'] = allGoodExoplanets['pl_radeerr2'].to_numpy()\n",
    "allGoodExoplanetsTable['Right Ascension'] = allGoodExoplanets[\"ra\"].to_numpy() * units.deg\n",
    "allGoodExoplanetsTable['Declination'] = allGoodExoplanets[\"dec\"].to_numpy() * units.deg\n",
    "allGoodExoplanetsTable['GAIA Magnitude'] = allGoodExoplanets[\"sy_gaiamag\"].to_numpy()\n",
    "allGoodExoplanetsTable['Insolation'] = allGoodExoplanets['pl_insol'].to_numpy()\n",
    "\n",
    "# Filter out exoplanet hosting stars which don't have a GAIA magnitude\n",
    "allGoodExoplanetsTable = allGoodExoplanetsTable[(np.isnan(allGoodExoplanetsTable['GAIA Magnitude']) == False)]\n",
    "\n",
    "# Filter out exoplanet hosting stars which don't have a radius or mass or density\n",
    "allGoodExoplanetsTable = allGoodExoplanetsTable[(np.isnan(allGoodExoplanetsTable['Radius (Earth)']) == False)]\n",
    "allGoodExoplanetsTable = allGoodExoplanetsTable[(np.isnan(allGoodExoplanetsTable['Mass (Earth)']) == False)]\n",
    "# allGoodExoplanetsTable = allGoodExoplanetsTable[(np.isnan(allGoodExoplanetsTable['Density']) == False)]\n",
    "allGoodExoplanetsTable = allGoodExoplanetsTable[(np.isnan(allGoodExoplanetsTable['Insolation']) == False)]\n",
    "\n",
    "print(\"Amount of exoplanet hosting stars relevant to my search (includes duplicates purposefully ofc): \"+str(len(allGoodExoplanetsTable)) +\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# -------------------------- Get star properties --------------------------\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "# Initialise GAIA star table\n",
    "gaiaExoplanetStars = QTable()\n",
    "\n",
    "# Query GAIA for each of these exoplanet hosting stars - create a table of all of the exoplanet hosting stars and their properties\n",
    "gaiaExoplanetStars = getGAIADataMultipleStars2(allGoodExoplanetsTable)\n",
    "\n",
    "# Print the stars returned from the query\n",
    "# print(\"All selected stars from GAIA archive: (Total = \", len(gaiaExoplanetStars), \")\")\n",
    "# print(\"Total:\", len(gaiaExoplanetStars))\n",
    "# gaiaExoplanetStars.pprint(max_width=50000, max_lines=5000)\n",
    "\n",
    "# print(\"All selected stars from the GAIA archive\")\n",
    "print(\"All selected stars from the GAIA archive:\", len(gaiaExoplanetStars))\n",
    "\n",
    "# Create a copy of the star data but only for ones with metallicity values - Filter out stars with no alphafe_gspspec metallicity or Fe metallicity\n",
    "gaiaExoplanetStarsWithMetallicities = gaiaExoplanetStars[(gaiaExoplanetStars['mh_gspphot'].mask == False)]\n",
    "# gaiaExoplanetStarsWithMetallicities = gaiaExoplanetStarsWithMetallicities[(gaiaExoplanetStarsWithMetallicities['alphafe_gspspec'].mask == False)]\n",
    "\n",
    "print(\"All selected stars from the GAIA archive with Fe/H values\")\n",
    "print(\"Total:\", len(gaiaExoplanetStarsWithMetallicities))\n",
    "# gaiaExoplanetStarsWithMetallicities.pprint(max_width=50000, max_lines=5000)\n",
    "\n",
    "# Go through all of the exoplanets in the table and add star details. Compiles a list of planets with star data\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# --------------------- Match planets to their stars ---------------------\n",
    "# ------------------------------------------------------------------------\n",
    "print(\"Matching planets to their stars\")\n",
    "\n",
    "print(\"There are\", len(allGoodExoplanetsTable), \"planets\")\n",
    "allGoodExoplanetsWithStarData = QTable()\n",
    "bFirstRowAdded = False\n",
    "\n",
    "# Box width for filtering\n",
    "width=8*units.arcsecond\n",
    "\n",
    "# Go through all of the exoplanets\n",
    "for i in range(len(allGoodExoplanetsTable)):\n",
    "    print(\"Planet\", i, \"| GAIA magnitude =\", allGoodExoplanetsTable[i]['GAIA Magnitude'])\n",
    "    # Go through all of the stars and find the correct one for the planet\n",
    "    for j in range(len(gaiaExoplanetStarsWithMetallicities)):\n",
    "        # If this star is the one for the planet, add the stars details to the planet\n",
    "        if (gaiaExoplanetStarsWithMetallicities[j]['phot_g_mean_mag'] <= allGoodExoplanetsTable[i]['GAIA Magnitude'] + 0.5 and\n",
    "            gaiaExoplanetStarsWithMetallicities[j]['phot_g_mean_mag'] >= allGoodExoplanetsTable[i]['GAIA Magnitude'] - 0.5 and\n",
    "            gaiaExoplanetStarsWithMetallicities[j][GaiaClass.MAIN_GAIA_TABLE_RA] <= (allGoodExoplanetsTable[i]['Right Ascension'] + width).value and\n",
    "            gaiaExoplanetStarsWithMetallicities[j][GaiaClass.MAIN_GAIA_TABLE_RA] >= (allGoodExoplanetsTable[i]['Right Ascension'] - width).value and \n",
    "            gaiaExoplanetStarsWithMetallicities[j][GaiaClass.MAIN_GAIA_TABLE_DEC] <= (allGoodExoplanetsTable[i]['Declination'] + width).value and\n",
    "            gaiaExoplanetStarsWithMetallicities[j][GaiaClass.MAIN_GAIA_TABLE_DEC] >= (allGoodExoplanetsTable[i]['Declination'] - width).value):\n",
    "            \n",
    "            # Combines the exoplanet's own data with its star's data\n",
    "            hostStarData = gaiaExoplanetStarsWithMetallicities[j]\n",
    "            exoplanetAndHostStar = hstack([hostStarData, allGoodExoplanetsTable[i]])\n",
    "\n",
    "            # And add to the list of planets\n",
    "            if (bFirstRowAdded):\n",
    "                allGoodExoplanetsWithStarData = vstack([allGoodExoplanetsWithStarData, exoplanetAndHostStar])\n",
    "                print(\"Star identified\")\n",
    "            else:\n",
    "                allGoodExoplanetsWithStarData = exoplanetAndHostStar\n",
    "                bFirstRowAdded = True\n",
    "                print(\"Star identified\")\n",
    "            \n",
    "            # Stops the inner for loop if a star for that planet was found - if there were 2 matches (which there would be in some instances because some stars are duplicated) then it just takes the first one as the correct one for the planet\n",
    "            break\n",
    "\n",
    "print(\"There are\", len(allGoodExoplanetsWithStarData), \"planets with star data\")\n",
    "\n",
    "# Can now plot the planets with their star data, from allGoodExoplanetsWithStarData\n",
    "# Or filter, or calculate errors etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7164d82",
   "metadata": {},
   "source": [
    "### Filtering, adding new columns, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d3ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# --------------- Deal with the data, analyse, filter, etc. ---------------\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "# Calculate Fe/H errors, and filter\n",
    "allGoodExoplanetsWithStarData['FeHErrorsUp'] = allGoodExoplanetsWithStarData['mh_gspphot_upper'] - allGoodExoplanetsWithStarData['mh_gspphot']\n",
    "allGoodExoplanetsWithStarData['FeHErrorsLow'] = allGoodExoplanetsWithStarData['mh_gspphot'] - allGoodExoplanetsWithStarData['mh_gspphot_lower']\n",
    "allGoodExoplanetsWithStarData = allGoodExoplanetsWithStarData[allGoodExoplanetsWithStarData['FeHErrorsUp'] < 0.1]\n",
    "allGoodExoplanetsWithStarData = allGoodExoplanetsWithStarData[allGoodExoplanetsWithStarData['FeHErrorsLow'] < 0.1]\n",
    "\n",
    "\n",
    "# Calculate Alpha/Fe errors\n",
    "allGoodExoplanetsWithStarData['AlphaFeErrorsUp'] = allGoodExoplanetsWithStarData['alphafe_gspspec_upper'] - allGoodExoplanetsWithStarData['alphafe_gspspec']\n",
    "allGoodExoplanetsWithStarData['AlphaFeErrorsLow'] = allGoodExoplanetsWithStarData['alphafe_gspspec'] - allGoodExoplanetsWithStarData['alphafe_gspspec_lower']\n",
    "\n",
    "# Create the new columns for galactic velocities\n",
    "allGoodExoplanetsWithStarData['U'] = np.empty((len(allGoodExoplanetsWithStarData)))\n",
    "allGoodExoplanetsWithStarData['UErr'] = np.empty((len(allGoodExoplanetsWithStarData)))\n",
    "allGoodExoplanetsWithStarData['V'] = np.empty((len(allGoodExoplanetsWithStarData)))\n",
    "allGoodExoplanetsWithStarData['VErr'] = np.empty((len(allGoodExoplanetsWithStarData)))\n",
    "allGoodExoplanetsWithStarData['W'] = np.empty((len(allGoodExoplanetsWithStarData)))\n",
    "allGoodExoplanetsWithStarData['WErr'] = np.empty((len(allGoodExoplanetsWithStarData)))\n",
    "allGoodExoplanetsWithStarData['Speed'] = np.empty((len(allGoodExoplanetsWithStarData)))\n",
    "allGoodExoplanetsWithStarData['SpeedErr'] = np.empty((len(allGoodExoplanetsWithStarData)))\n",
    "\n",
    "# Go through all stars, calculate galactic velocities\n",
    "print(\"Calculating galactic velocities\")\n",
    "for i in range (len(allGoodExoplanetsWithStarData)):\n",
    "    gaiaStar = allGoodExoplanetsWithStarData[i]\n",
    "    \n",
    "    galacticVelocity = computeGalacticVelocity(gaiaStar)\n",
    "    allGoodExoplanetsWithStarData['U'][i] = galacticVelocity[0]\n",
    "    allGoodExoplanetsWithStarData['UErr'][i] = galacticVelocity[1]\n",
    "    allGoodExoplanetsWithStarData['V'][i] = galacticVelocity[2]\n",
    "    allGoodExoplanetsWithStarData['VErr'][i] = galacticVelocity[3]\n",
    "    allGoodExoplanetsWithStarData['W'][i] = galacticVelocity[4]\n",
    "    allGoodExoplanetsWithStarData['WErr'][i] = galacticVelocity[5]\n",
    "    allGoodExoplanetsWithStarData['Speed'][i] = (galacticVelocity[0]**2 + galacticVelocity[2]**2 + galacticVelocity[4]**2)**(0.5)\n",
    "    allGoodExoplanetsWithStarData['SpeedErr'][i] = (galacticVelocity[1]**2 + galacticVelocity[3]**2 + galacticVelocity[5]**2)**(0.5) # Is this even correct\n",
    "\n",
    "# Print number of final stars\n",
    "print(\"There are now\", len(allGoodExoplanetsWithStarData), \"planets with star data\")\n",
    "\n",
    "# Start plotting the data in various ways\n",
    "\n",
    "planetDensity = allGoodExoplanetsWithStarData['Density']\n",
    "planetDensityLabel = \"Planet Density (g/cm$^{3}$)\"\n",
    "planetDensityError = np.stack((allGoodExoplanetsWithStarData['Density Error Up'].value, -1 * allGoodExoplanetsWithStarData['Density Error Down'].value))\n",
    "\n",
    "planetMass = allGoodExoplanetsWithStarData['Mass (Earth)']\n",
    "planetMassLabel = \"Planet Mass (M$_{\\oplus}$)\"\n",
    "planetMassError = np.stack((allGoodExoplanetsWithStarData['Mass (Earth) Error Up'].value, -1 * allGoodExoplanetsWithStarData['Mass (Earth) Error Down'].value))\n",
    "\n",
    "planetRadius = allGoodExoplanetsWithStarData['Radius (Earth)']\n",
    "planetRadiusLabel = \"Planet Radius (R$_{\\oplus}$)\"\n",
    "planetRadiusError = np.stack((allGoodExoplanetsWithStarData['Radius (Earth) Error Up'].value, -1 * allGoodExoplanetsWithStarData['Radius (Earth) Error Down'].value))\n",
    "\n",
    "#yError = galacticSpeeds.T[1]\n",
    "#fullYError = np.stack((yError, yError))\n",
    "\n",
    "FeHMetallicity = allGoodExoplanetsWithStarData['mh_gspphot'].value\n",
    "FeHMetalicityLabel = \"[Fe/H] Metallicity (Dex)\"\n",
    "FeHMetallicityError = np.stack((allGoodExoplanetsWithStarData['FeHErrorsLow'].value, allGoodExoplanetsWithStarData['FeHErrorsUp'].value))\n",
    "\n",
    "AlphaFeMetallicity = allGoodExoplanetsWithStarData['alphafe_gspspec'].value\n",
    "AlphaFeMetalicityLabel = \"[Alpha/Fe] Metallicity (Dex)\"\n",
    "AlphaFeMetallicityError = np.stack((allGoodExoplanetsWithStarData['AlphaFeErrorsLow'].value, allGoodExoplanetsWithStarData['AlphaFeErrorsUp'].value))\n",
    "\n",
    "U = allGoodExoplanetsWithStarData['U'].value\n",
    "UErr = np.stack((allGoodExoplanetsWithStarData['UErr'].value, allGoodExoplanetsWithStarData['UErr'].value))\n",
    "V = allGoodExoplanetsWithStarData['V'].value\n",
    "VErr = np.stack((allGoodExoplanetsWithStarData['VErr'].value, allGoodExoplanetsWithStarData['VErr'].value))\n",
    "W = allGoodExoplanetsWithStarData['W'].value\n",
    "WErr = np.stack((allGoodExoplanetsWithStarData['WErr'].value, allGoodExoplanetsWithStarData['WErr'].value))\n",
    "Speed = allGoodExoplanetsWithStarData['Speed'].value\n",
    "SpeedErr = np.stack((allGoodExoplanetsWithStarData['SpeedErr'].value, allGoodExoplanetsWithStarData['SpeedErr'].value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e017aa",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b831d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allGoodExoplanetsWithStarData.pprint_all()\n",
    "\n",
    "print(\"Size of planet and star data:\", str(len(allGoodExoplanetsWithStarData)))\n",
    "print(\"Size of metallicities:\", str(len(FeHMetallicity)))\n",
    "\n",
    "# Make copies of it and each copy filter a different range:\n",
    "# Needs to be before the referencing. Well, since the referencing will need to be added to the loop anyway we might as well delete the rereferencing, or at least just reference the table directly for the for loop ones\n",
    "\n",
    "\n",
    "planetsAndTheirHostsRadiiRange = allGoodExoplanetsWithStarData[allGoodExoplanetsWithStarData['Insolation'] >= 250]\n",
    "\n",
    "\n",
    "# For each radius range\n",
    "for i in range(1):\n",
    "    i = 2\n",
    "    if (i == 0):\n",
    "        planetsAndTheirHostsRadiiRange = planetsAndTheirHostsRadiiRange[planetsAndTheirHostsRadiiRange['Radius (Earth)'] <= 3]\n",
    "    elif (i == 1):\n",
    "        planetsAndTheirHostsRadiiRange = planetsAndTheirHostsRadiiRange[planetsAndTheirHostsRadiiRange['Mass (Earth)'] >= 130]\n",
    "        planetsAndTheirHostsRadiiRange = planetsAndTheirHostsRadiiRange[planetsAndTheirHostsRadiiRange['Mass (Earth)'] <= 520]\n",
    "        # planetsAndTheirHostsRadiiRange = planetsAndTheirHostsRadiiRange[planetsAndTheirHostsRadiiRange['Mass (Earth)'] >= 300]\n",
    "        # planetsAndTheirHostsRadiiRange = planetsAndTheirHostsRadiiRange[planetsAndTheirHostsRadiiRange['Density'] <= 1]\n",
    "    elif (i == 2):\n",
    "        planetsAndTheirHostsRadiiRange = allGoodExoplanetsWithStarData\n",
    "    \n",
    "    \n",
    "    # For each of the planet parameters\n",
    "    # for j in range(1):\n",
    "    szParameter = \"mass\"\n",
    "    if (szParameter == \"radius\"):\n",
    "        yData = planetsAndTheirHostsRadiiRange['Radius (Earth)']\n",
    "        yLabel = planetRadiusLabel\n",
    "        yError = np.stack((planetsAndTheirHostsRadiiRange['Radius (Earth) Error Up'].value, -1 * planetsAndTheirHostsRadiiRange['Radius (Earth) Error Down'].value))\n",
    "        logariseY = False\n",
    "    \n",
    "    elif (szParameter == \"mass\"):\n",
    "        yData = planetsAndTheirHostsRadiiRange['Mass (Earth)']\n",
    "        yLabel = planetMassLabel\n",
    "        yError = np.stack((planetsAndTheirHostsRadiiRange['Mass (Earth) Error Up'].value, -1 * planetsAndTheirHostsRadiiRange['Mass (Earth) Error Down'].value))\n",
    "        logariseY = True\n",
    "    \n",
    "    elif (szParameter == \"density\"):\n",
    "        yData = planetsAndTheirHostsRadiiRange['Density'].value\n",
    "        yLabel = planetDensityLabel\n",
    "        yError = np.stack((planetsAndTheirHostsRadiiRange['Density Error Up'].value, -1 * planetsAndTheirHostsRadiiRange['Density Error Down'].value))\n",
    "        logariseY = True\n",
    "\n",
    "    # For each of the star parameters\n",
    "    # for k in range(2):\n",
    "    k = 0\n",
    "    if (k == 0):\n",
    "        xData = planetsAndTheirHostsRadiiRange['mh_gspphot'].value\n",
    "        xLabel = FeHMetalicityLabel\n",
    "        xError = np.stack((planetsAndTheirHostsRadiiRange['FeHErrorsLow'].value, planetsAndTheirHostsRadiiRange['FeHErrorsUp'].value))\n",
    "    # elif (k == 1):\n",
    "    #     xData = planetsAndTheirHostsRadiiRange['alphafe_gspspec'].value\n",
    "    #     xLabel = \"[Alpha/Fe] Metallicity (Dex)\"\n",
    "    #     xError = np.stack((planetsAndTheirHostsRadiiRange['AlphaFeErrorsLow'].value, planetsAndTheirHostsRadiiRange['AlphaFeErrorsUp'].value))\n",
    "    # elif (k == 2):\n",
    "    #     xData = planetsAndTheirHostsRadiiRange['U'].value\n",
    "    #     xLabel = \"U [km/s]\"\n",
    "    #     xError = np.stack((planetsAndTheirHostsRadiiRange['UErr'].value, planetsAndTheirHostsRadiiRange['UErr'].value))\n",
    "    # elif (k == 3):\n",
    "    #     xData = planetsAndTheirHostsRadiiRange['V'].value\n",
    "    #     xLabel = \"V [km/s]\"\n",
    "    #     xError = np.stack((planetsAndTheirHostsRadiiRange['VErr'].value, planetsAndTheirHostsRadiiRange['VErr'].value))\n",
    "    # elif (k == 4):\n",
    "    #     xData = planetsAndTheirHostsRadiiRange['W'].value\n",
    "    #     xLabel = \"W [km/s]\"\n",
    "    #     xError = np.stack((planetsAndTheirHostsRadiiRange['WErr'].value, planetsAndTheirHostsRadiiRange['WErr'].value))\n",
    "    # else:\n",
    "    #     xData = planetsAndTheirHostsRadiiRange['Speed'].value\n",
    "    #     xLabel = \"Speed [km/s]\"\n",
    "    #     xError = np.stack((planetsAndTheirHostsRadiiRange['SpeedErr'].value, planetsAndTheirHostsRadiiRange['SpeedErr'].value))\n",
    "\n",
    "    # Creates a scatter graph\n",
    "    # if i==0:\n",
    "    #     szGraphTitle = (yLabel +\" vs \" +xLabel +\" with radius <= 3 Re\")\n",
    "    # elif i==1:\n",
    "    #     szGraphTitle = (yLabel +\" vs \" +xLabel +\" with density between 0 and 1.5 g/cm^3\")\n",
    "    #     # planetsAndTheirHostsRadiiRange.pprint()\n",
    "    # elif i==2:\n",
    "    #     szGraphTitle = (yLabel +\" vs \" +xLabel +\" with $x$ density >= 2.25 g/cm^3\")\n",
    "    #     szGraphTitle = (yLabel +\" vs \" +xLabel +\" with errors less than 20%\")\n",
    "\n",
    "\n",
    "    # Edit this\n",
    "    szColourAxis = \"insolation\"\n",
    "    bColourLoggersised = True\n",
    "\n",
    "    if (szColourAxis == \"mass\"):\n",
    "        colourData = planetsAndTheirHostsRadiiRange['Mass (Earth)'].value\n",
    "        colourLabel = planetMassLabel\n",
    "    if (szColourAxis == \"radius\"):\n",
    "        colourData = planetsAndTheirHostsRadiiRange['Radius (Earth)'].value\n",
    "        colourLabel = planetRadiusLabel\n",
    "    if (szColourAxis == \"density\"):\n",
    "        colourData = planetsAndTheirHostsRadiiRange['Density'].value\n",
    "        colourLabel = planetDensityLabel\n",
    "    if (szColourAxis == \"insolation\"):\n",
    "        colourData = planetsAndTheirHostsRadiiRange['Insolation'].value\n",
    "        colourLabel = \"Insolation [Insol Units]\"\n",
    "    \n",
    "    \n",
    "    # CBA to go through and comment them all out\n",
    "    szGraphTitle = \"\"\n",
    "\n",
    "    logariseY = False\n",
    "    \n",
    "    # plt.show()\n",
    "    # print(colourData)\n",
    "        \n",
    "    figure = plotScatterGraphOfData(szTitle=\"\", xAxis=xLabel, yAxis=yLabel, xData=xData, yData=yData, xError=xError, yError=yError,\n",
    "                                    logariseXAxis=False, logariseYAxis=logariseY, colours=colourData, colourAxisLabel=colourLabel, bColourLoggersised=bColourLoggersised, \n",
    "                                    sizes=planetsAndTheirHostsRadiiRange['Radius (Earth)']*0.2, tickSeperation = 0.5)\n",
    "\n",
    "    # if (i==2 and j == 0):\n",
    "    #     axes.hlines(y = [0.5, 10.7, 5.7, 19.3, 2.65, 4.85], colors=['b', 'b', 'r', 'r', 'g', 'g'], linestyles='dashed', xmin=-1.4, xmax=0.9)\n",
    "    \n",
    "    bbox = Bbox.from_bounds(0, 0, 3.2, 2.4)\n",
    "    bbox = Bbox.from_bounds(0.26, -0.2, *bbox.size)\n",
    "    tightbbox = figure.get_tightbbox(figure.canvas.get_renderer())\n",
    "    print(tightbbox)\n",
    "    # just set it directly to figure size\n",
    "    figure.set(figheight=tightbbox.height, figwidth=tightbbox.width)\n",
    "    print(figure.get_figwidth())\n",
    "    \n",
    "    figure.savefig(fname = \"Graphs/s.pdf\", format=\"pdf\", bbox_inches=bbox)\n",
    "    figure.show()\n",
    "\n",
    "    # saveGraph(\"Exported graph\", \"pdf\")\n",
    "\n",
    "    parameters, rho_post = MCMC_model(xData, yData)\n",
    "    \n",
    "    szLine = \"%ld %.3lf %.3lf %.3lf %.3lf %.3lf\" % (len(planetsAndTheirHostsRadiiRange), parameters[0], parameters[1], parameters[2], parameters[3], (parameters[0]/parameters[1]))\n",
    "    print(szLine)\n",
    "    plt.figure(dpi=100)\n",
    "    plt.hist(rho_post, range = (-0.8, 0.8), bins=100)\n",
    "    plt.title(szGraphTitle)\n",
    "\n",
    "print(np.average(planetsAndTheirHostsRadiiRange['Density'].value))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb6e562",
   "metadata": {},
   "source": [
    "## Analysis of the switch point for radii for radii against Fe/H\n",
    "#### The range R > will be varied and the curve plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a90374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the start value for the lower limit. Is increased until lowerUpperLimit\n",
    "currentLowerLimit = 0\n",
    "\n",
    "# Defines the bounds of the correlation space\n",
    "lowerUpperLimit = 25\n",
    "upperUpperLimit = 25\n",
    "newLength = 0\n",
    "\n",
    "\n",
    "def stepUp(currentLimit):\n",
    "    # # Masses\n",
    "    # if (currentLimit < 10):\n",
    "    #     limitMove = 0.04\n",
    "    # elif (currentLimit < 50):\n",
    "    #     limitMove = 0.04\n",
    "    # elif (currentLimit < 200):\n",
    "    #     limitMove = 0.4\n",
    "    # elif (currentLimit < 5000):\n",
    "    #     limitMove = 40\n",
    "    # else:\n",
    "    #     limitMove = 400\n",
    "\n",
    "    # Radii\n",
    "    if (currentLimit < 15):\n",
    "        limitMove = 0.01\n",
    "    else:\n",
    "        limitMove = 0.1\n",
    "\n",
    "    # Densities (Already been modified to increase resolution) - this was without the 6 cores though, so I'm going to increase resolution further\n",
    "    # if (currentLimit < 4.99):\n",
    "    #     limitMove = 0.002\n",
    "    # elif (currentLimit < 10.99):\n",
    "    #     limitMove = 0.02\n",
    "    # elif (currentLimit < 14.99):\n",
    "    #     limitMove = 0.04\n",
    "    # else:\n",
    "    #     limitMove = 1\n",
    "\n",
    "    # 900,000 with radii\n",
    "    # if (currentLimit < 4.99):\n",
    "    #     limitMove = 0.004\n",
    "    # elif (currentLimit < 10.99):\n",
    "    #     limitMove = 0.05\n",
    "    # elif (currentLimit < 14.99):\n",
    "    #     limitMove = 0.08\n",
    "    # else:\n",
    "    #     limitMove = 1\n",
    "\n",
    "    # if (currentLimit < 4.99):\n",
    "    #     limitMove = 0.005\n",
    "    # elif (currentLimit < 10.99):\n",
    "    #     limitMove = 0.1\n",
    "    # elif (currentLimit < 14.99):\n",
    "    #     limitMove = 0.2\n",
    "    # else:\n",
    "    #     limitMove = 1\n",
    "    \n",
    "    \n",
    "    return limitMove\n",
    "\n",
    "\n",
    "# Loops over the upper limit\n",
    "def innerLoop(currentLowerLimit):\n",
    "    # Start the upper limit at the top values, then slowly decrease it \n",
    "    currentUpperLimit = upperUpperLimit\n",
    "\n",
    "    #Resets the list to include everything above the lower limit\n",
    "    planetsAndTheirHostsLowerPlanetsExcluded = allGoodExoplanetsWithStarData[allGoodExoplanetsWithStarData['Radius (Earth)'] >= currentLowerLimit]\n",
    "    # Stores the content of one inner loop (so multiple lines) before writting them all in one go\n",
    "    szOneInnerLoop= \"\"\n",
    "\n",
    "    while currentUpperLimit > currentLowerLimit: # Iterate from upperUpperLimit to currentLowerLimit\n",
    "        # Restrticts the list to be everything under the upper limit\n",
    "        planetsAndTheirHostsRadiiRange = planetsAndTheirHostsLowerPlanetsExcluded[planetsAndTheirHostsLowerPlanetsExcluded['Radius (Earth)'] <= currentUpperLimit]\n",
    "        \n",
    "        if (len(planetsAndTheirHostsRadiiRange) < 8): # Fck it because we really don't use these 5 ones\n",
    "            currentUpperLimit = currentUpperLimit - stepUp(currentUpperLimit)\n",
    "            # print(\"Not enough planets in range\", currentLowerLimit, upperLowerLimit)\n",
    "            # continue\n",
    "            break # we can now break because we know any ranges below this will also not have 5 planets since we only reduce the range within this inner loop\n",
    "        \n",
    "        # if (newLength != lengthStore):\n",
    "        parameters, rho_post = MCMC_model(planetsAndTheirHostsRadiiRange['mh_gspphot'].value, planetsAndTheirHostsRadiiRange['Mass (Earth)'].value)\n",
    "        \n",
    "        szLine = \"%.2lf %.2lf %ld %.3lf %.3lf %.3lf %.3lf %.3lf\" % (currentLowerLimit, currentUpperLimit, len(planetsAndTheirHostsRadiiRange), parameters[0], parameters[1], parameters[2], parameters[3], (parameters[0]/parameters[1]))\n",
    "        # print(szLine)\n",
    "        szOneInnerLoop = \"\\n\".join([szOneInnerLoop, szLine]) \n",
    "        # print(\"The mean over the std (mean/std) is %.3f\" % (parameters[0]/parameters[1]))\n",
    "        # np.savetxt(\"rho_summary.csv\", rho_post, fmt=\"%d\", delimiter=\",\") #saving the results on .csv format\n",
    "        currentUpperLimit = currentUpperLimit - stepUp(currentUpperLimit)\n",
    "        # lengthStore = newLength\n",
    "        # plt.figure(dpi=100)\n",
    "        # plt.hist(rho_post, range = (-0.8, 0.8), bins=80)\n",
    "        # plt.title((\"Radius vs Fe/H for radius >= 1.2 and <=\" + str(upperLimit).format(\"%.2lf\") + \"Re\"))\n",
    "        # plt.show()\n",
    "    \n",
    "    szOutputMessage = \"Loop for lower limit = \" + (\"%.3lf \" % (currentLowerLimit)) + \"finished\"\n",
    "    print(szOutputMessage)\n",
    "    file = open(\"FeH vs Mass for all Radius ranges (more than 250 Insolation).txt\", \"a\")\n",
    "    file.write(szOneInnerLoop)\n",
    "    file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a075de49",
   "metadata": {},
   "source": [
    "### The actual runthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7456e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from multiprocessing import Pool\n",
    "# from multiprocess import Pool\n",
    "from multiprocess import Process\n",
    "\n",
    "#This will use six cores. Add or remove to use more.\n",
    "while currentLowerLimit <= lowerUpperLimit:\n",
    "    process1 = Process(target=innerLoop, args=[currentLowerLimit])\n",
    "    currentLowerLimit = currentLowerLimit + stepUp(currentLowerLimit)\n",
    "    process1.start()\n",
    "\n",
    "    process2 = Process(target=innerLoop, args=[currentLowerLimit])\n",
    "    currentLowerLimit = currentLowerLimit + stepUp(currentLowerLimit)\n",
    "    process2.start()\n",
    "\n",
    "    process3 = Process(target=innerLoop, args=[currentLowerLimit])\n",
    "    currentLowerLimit = currentLowerLimit + stepUp(currentLowerLimit)\n",
    "    process3.start()\n",
    "\n",
    "    process4 = Process(target=innerLoop, args=[currentLowerLimit])\n",
    "    currentLowerLimit = currentLowerLimit + stepUp(currentLowerLimit)\n",
    "    process4.start()\n",
    "\n",
    "    process5 = Process(target=innerLoop, args=[currentLowerLimit])\n",
    "    currentLowerLimit = currentLowerLimit + stepUp(currentLowerLimit)\n",
    "    process5.start()\n",
    "\n",
    "    process6 = Process(target=innerLoop, args=[currentLowerLimit])\n",
    "    currentLowerLimit = currentLowerLimit + stepUp(currentLowerLimit)\n",
    "    process6.start()\n",
    "\n",
    "    process1.join()\n",
    "    process2.join()\n",
    "    process3.join()\n",
    "    process4.join()\n",
    "    process5.join()\n",
    "    process6.join()\n",
    "\n",
    "\n",
    "# #Create all processes in one go\n",
    "# # create the process pool with 4 cores\n",
    "# allLowerLimits = np.array([currentLowerLimit])\n",
    "# while currentLowerLimit <= lowerUpperLimit:\n",
    "#     currentLowerLimit = currentLowerLimit + stepUp(currentLowerLimit)\n",
    "#     allLowerLimits = np.append(allLowerLimits, [currentLowerLimit])\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     thePool = Pool(4)\n",
    "\n",
    "#     thePool.map_async(func=innerLoop, iterable=allLowerLimits)\n",
    "\n",
    "#     thePool.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adca15a5",
   "metadata": {},
   "source": [
    "## Peforms the analysis steps for Planet-Planet Properties\n",
    "This can be edited as you see fit. If extra features need to be added to a graph, do it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d2e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# --------------------- Planet property quality cuts ---------------------\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "allGraphData = allNonControversialAndDefaultData[allNonControversialAndDefaultData['pl_denslim'] != 1]\n",
    "allGraphData = allGraphData[allGraphData['pl_masselim'] != 1]\n",
    "allGraphData = allGraphData[allGraphData['st_metlim'] != 1]\n",
    "allGraphData = allGraphData[allGraphData['pl_insollim'] != 1]\n",
    "allGraphData = allGraphData[allGraphData['st_metratio'] == \"[Fe/H]\"]\n",
    "# allGraphData = allGraphData[allGraphData['pl_dens'] < 8]\n",
    "allGraphData = allGraphData[allGraphData['pl_masse'] <= 20]\n",
    "allGraphData = allGraphData[allGraphData['pl_insol'] > -1]\n",
    "\n",
    "# Remove uncertain data\n",
    "allGraphData = allGraphData[allGraphData['pl_masseerr1']/allGraphData['pl_masse'] < 0.2]\n",
    "allGraphData = allGraphData[allGraphData['pl_masseerr2']/allGraphData['pl_masse'] < 0.2]\n",
    "\n",
    "allGraphData = allGraphData[allGraphData['st_meterr1'] < 0.2]\n",
    "allGraphData = allGraphData[allGraphData['st_meterr2'] < 0.2]\n",
    "\n",
    "# allGraphData = allGraphData[allGraphData['pl_denserr1']/allGraphData['pl_dens'] < 0.2]\n",
    "# allGraphData = allGraphData[allGraphData['pl_denserr2']/allGraphData['pl_dens'] < 0.2]\n",
    "\n",
    "# Create a colour dictionary of detection methods\n",
    "# colours = detectionMethodColourDictionary(allGraphData)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# ----------------------- Planet property plotting -----------------------\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# Specify the axes\n",
    "yLabel = \"Planet Mass [Earth Masses]\"\n",
    "yField = \"pl_masse\"\n",
    "\n",
    "xLabel = \"Stellar Metalilcity [dex]\"\n",
    "xField = \"st_met\"\n",
    "# yLabel = \"Planet Density\"\n",
    "# yField = \"pl_dens\"\n",
    "\n",
    "# Add the colour dimension\n",
    "colours = allGraphData['pl_insol']\n",
    "colourAxisLabel = \"Planet Insolation\"\n",
    "\n",
    "# Extracts the errors - Yes, down is 2 and up is 1\n",
    "xErrorDown = (allGraphData[xField+\"err2\"] * -1).to_numpy()\n",
    "xErrorUp = allGraphData[xField+\"err1\"].to_numpy()\n",
    "xError = np.stack((xErrorDown, xErrorUp))\n",
    "\n",
    "yErrorDown = (allGraphData[yField+\"err2\"] * -1).to_numpy()\n",
    "yErrorUp = allGraphData[yField+\"err1\"].to_numpy()\n",
    "yError = np.stack((yErrorDown, yErrorUp))\n",
    "\n",
    "\n",
    "# Creates a scatter graph\n",
    "plotScatterGraphOfData(szGraphTitle, xLabel, yLabel, allGraphData[xField], allGraphData[yField], xError, yError, False, True,\n",
    "                      colours=colours.to_numpy(), colourAxisLabel = colourAxisLabel)\n",
    "\n",
    "# iMax = 0\n",
    "# iMin = 99999999999\n",
    "# for i in colours:\n",
    "#     if i < iMin:\n",
    "#         iMin = i\n",
    "#     if i > iMax:\n",
    "#         iMax = i\n",
    "\n",
    "# print(iMax)\n",
    "# print(iMin)\n",
    "\n",
    "\n",
    "#plt.legend(\"Discovery Methods\")\n",
    "#plt.legend(\"Red = Radial Velocity\")\n",
    "#plt.legend(\"Blue = Transit\")\n",
    "#plt.legend(\"Green = Imaging\")\n",
    "#plt.legend(\"Magenta = Other\")\n",
    "\n",
    "# Saves the graph\n",
    "# saveGraph(saveFileName, \"png\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "###########Analsyis 2 - the planet boi one\n",
    "\n",
    "        # This is here because we only want a list of densities for the planets where the stars metallicity data is good quality\n",
    "        # Density quality was ensured before the query was even sent so that is already intrinsic to this data\n",
    "    #    PlanetDensitiesErrorsUp = np.append(PlanetDensitiesErrorsUp, allGoodExoplanets['pl_denserr1'].iloc[i])\n",
    "    #    PlanetDensitiesErrorsLow = np.append(PlanetDensitiesErrorsLow, allGoodExoplanets['pl_denserr2'].iloc[i]*-1)\n",
    "    #    PlanetDensities = np.append(PlanetDensities, allGoodExoplanets['pl_dens'].iloc[i])\n",
    "#\n",
    "    #    colourData = np.append(colourData, allGoodExoplanetsTable['masse'][i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request and download GAIA data for exoplanet hosting stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the exoplanets\n",
    "allGoodExoplanets = allNonControversialAndDefaultData\n",
    "\n",
    "# Extract the coordinates and gaia magnitudes of all of the NASA exoplanet hosting stars\n",
    "RAs = allGoodExoplanets[\"ra\"]\n",
    "Decs = allGoodExoplanets[\"dec\"]\n",
    "gaiaMagnitudesNasa = allGoodExoplanets[\"sy_gaiamag\"]\n",
    "\n",
    "# Remove duplicate stars\n",
    "index = -1\n",
    "for i in range (len(RAs) - 1):\n",
    "    index = index + 1\n",
    "    if RAs.iloc[index+1] == RAs.iloc[index]:\n",
    "        if Decs.iloc[index+1] == Decs.iloc[index]:\n",
    "            if gaiaMagnitudesNasa.iloc[index+1] == gaiaMagnitudesNasa.iloc[index]:\n",
    "                szLabel = RAs.index[index+1]\n",
    "                RAs.drop(labels=szLabel, axis=\"index\", inplace=True)\n",
    "                Decs.drop(labels=szLabel, axis=\"index\", inplace=True)\n",
    "                gaiaMagnitudesNasa.drop(labels=szLabel, axis=\"index\", inplace=True)\n",
    "                index = index - 1\n",
    "\n",
    "print(\"Total exoplanet hosting stars:\", len(RAs))\n",
    "\n",
    "# Create astropy table from NASA data of exoplanet hosting stars\n",
    "coordsAndMagnitude = QTable()\n",
    "coordsAndMagnitude['Right Ascension'] = RAs.to_numpy() * units.deg\n",
    "coordsAndMagnitude['Declination'] = Decs.to_numpy() * units.deg\n",
    "coordsAndMagnitude['GAIA Magnitude'] = gaiaMagnitudesNasa.to_numpy()\n",
    "\n",
    "#coordsAndMagnitude.pprint(max_width=50000, max_lines=5000)\n",
    "\n",
    "# Filter out exoplanet hosting stars which don't have a GAIA magnitude\n",
    "coordsAndMagnitude = coordsAndMagnitude[(np.isnan(coordsAndMagnitude['GAIA Magnitude']) == False)]\n",
    "\n",
    "print(\"Total exoplanet hosting stars with GAIA magnitude:\", len(coordsAndMagnitude['GAIA Magnitude']))\n",
    "# coordsAndMagnitude.pprint(max_width=50000, max_lines=5000)\n",
    "\n",
    "# Initialise GAIA star table\n",
    "gaiaExoplanetStars = QTable()\n",
    "\n",
    "# Query GAIA for each of these exoplanet hosting stars - create a table of all of the exoplanet hosting stars and their properties\n",
    "gaiaExoplanetStars = getGAIADataMultipleStars2(coordsAndMagnitude)\n",
    "\n",
    "# Print the stars returned from the query\n",
    "print(\"All selected stars from GAIA archive: (Total = \", len(gaiaExoplanetStars), \")\")\n",
    "print(\"Total:\", len(gaiaExoplanetStars))\n",
    "gaiaExoplanetStars.pprint(max_width=50000, max_lines=5000)\n",
    "\n",
    "# Create a copy of the star data but only for ones with metallicity values -\n",
    "# (Filter out stars with no alphafe_gspspec metallicity or Fe metallicity)\n",
    "gaiaExoplanetStarsWithMetallicities = gaiaExoplanetStars[(gaiaExoplanetStars['alphafe_gspspec'].mask == False)]\n",
    "gaiaExoplanetStarsWithMetallicities = gaiaExoplanetStarsWithMetallicities[(gaiaExoplanetStarsWithMetallicities['mh_gspphot'].mask == False)]\n",
    "\n",
    "print(\"All selected stars from the GAIA archive with alpha/Fe and Fe/H values\")\n",
    "print(\"Total:\", len(gaiaExoplanetStarsWithMetallicities))\n",
    "gaiaExoplanetStarsWithMetallicities.pprint(max_width=50000, max_lines=5000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98290598",
   "metadata": {},
   "source": [
    "## Extract metallicities, calcluate galactic velocities from GAIA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de726d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "############### Analysis 1 - Metallicities and Galactic Velocities ###############\n",
    "##################################################################################\n",
    "\n",
    "# Create a copy of the star data for analysis 1\n",
    "gaiaStarsAnalysis1 = gaiaExoplanetStarsWithMetallicities.copy()\n",
    "\n",
    "# Filter on radial velocities\n",
    "gaiaStarsAnalysis1 = gaiaStarsAnalysis1[(gaiaStarsAnalysis1['radial_velocity'].mask == False)]\n",
    "\n",
    "# Calculate Fe/H errors\n",
    "gaiaStarsAnalysis1['FeHErrorsUp'] = gaiaStarsAnalysis1['mh_gspphot_upper'] - gaiaStarsAnalysis1['mh_gspphot']\n",
    "gaiaStarsAnalysis1['FeHErrorsLow'] = gaiaStarsAnalysis1['mh_gspphot'] - gaiaStarsAnalysis1['mh_gspphot_lower']\n",
    "\n",
    "# Filter on Fe/H errors - This is done immediately to reduce calculating data which is ultimately never needed\n",
    "gaiaStarsAnalysis1 = gaiaStarsAnalysis1[gaiaStarsAnalysis1['FeHErrorsUp'] < 0.04]\n",
    "gaiaStarsAnalysis1 = gaiaStarsAnalysis1[gaiaStarsAnalysis1['FeHErrorsLow'] < 0.04]\n",
    "\n",
    "# Calculate the Alpha/Fe errors\n",
    "gaiaStarsAnalysis1['AlphaFEErrorsUp'] = gaiaStarsAnalysis1['alphafe_gspspec_upper'] - gaiaStarsAnalysis1['alphafe_gspspec']\n",
    "gaiaStarsAnalysis1['AlphaFEErrorsLow'] = gaiaStarsAnalysis1['alphafe_gspspec'] - gaiaStarsAnalysis1['alphafe_gspspec_lower']\n",
    "\n",
    "# Filter on Alpha/Fe errors\n",
    "gaiaStarsAnalysis1 = gaiaStarsAnalysis1[gaiaStarsAnalysis1['AlphaFEErrorsUp'] < 0.2]\n",
    "gaiaStarsAnalysis1 = gaiaStarsAnalysis1[gaiaStarsAnalysis1['AlphaFEErrorsLow'] < 0.2]\n",
    "\n",
    "# Create the new columns\n",
    "gaiaStarsAnalysis1['U'] = np.empty((len(gaiaStarsAnalysis1)))\n",
    "gaiaStarsAnalysis1['UErr'] = np.empty((len(gaiaStarsAnalysis1)))\n",
    "gaiaStarsAnalysis1['V'] = np.empty((len(gaiaStarsAnalysis1)))\n",
    "gaiaStarsAnalysis1['VErr'] = np.empty((len(gaiaStarsAnalysis1)))\n",
    "gaiaStarsAnalysis1['W'] = np.empty((len(gaiaStarsAnalysis1)))\n",
    "gaiaStarsAnalysis1['WErr'] = np.empty((len(gaiaStarsAnalysis1)))\n",
    "gaiaStarsAnalysis1['Speed'] = np.empty((len(gaiaStarsAnalysis1)))\n",
    "gaiaStarsAnalysis1['SpeedErr'] = np.empty((len(gaiaStarsAnalysis1)))\n",
    "\n",
    "\n",
    "# Go through all stars, calculate galactic velocities\n",
    "for i in range (len(gaiaStarsAnalysis1)):\n",
    "    gaiaStar = gaiaStarsAnalysis1[i]\n",
    "    \n",
    "    galacticVelocity = computeGalacticVelocity(gaiaStar)\n",
    "    gaiaStarsAnalysis1['U'][i] = galacticVelocity[0]\n",
    "    gaiaStarsAnalysis1['UErr'][i] = galacticVelocity[1]\n",
    "    gaiaStarsAnalysis1['V'][i] = galacticVelocity[2]\n",
    "    gaiaStarsAnalysis1['VErr'][i] = galacticVelocity[3]\n",
    "    gaiaStarsAnalysis1['W'][i] = galacticVelocity[4]\n",
    "    gaiaStarsAnalysis1['WErr'][i] = galacticVelocity[5]\n",
    "    gaiaStarsAnalysis1['Speed'][i] = (galacticVelocity[0]**2 + galacticVelocity[2]**2 + galacticVelocity[4]**2)**(0.5)\n",
    "    gaiaStarsAnalysis1['SpeedErr'][i] = (galacticVelocity[1]**2 + galacticVelocity[3]**2 + galacticVelocity[5]**2)**(0.5) # Is this even correct\n",
    "\n",
    "# Set up metallicity axis\n",
    "metallicityLabel = \"[Fe/H] Metallicity\"\n",
    "metallicityData = gaiaStarsAnalysis1['mh_gspphot'].value\n",
    "metallicityError = np.stack((gaiaStarsAnalysis1['FeHErrorsLow'].value, gaiaStarsAnalysis1['FeHErrorsUp'].value))\n",
    "\n",
    "# Set up alpha/Fe axis\n",
    "alphaOnFeLabel = \"[Alpha/Fe] Metallicity\"\n",
    "alphaOnFeData = gaiaStarsAnalysis1['alphafe_gspspec'].value\n",
    "alphaOnFeError = np.stack((gaiaStarsAnalysis1['AlphaFEErrorsLow'].value, gaiaStarsAnalysis1['AlphaFEErrorsUp'].value))\n",
    "\n",
    "# Set up colour axis\n",
    "colourLabel = \"Galactic Speed [km/s]\"\n",
    "colourData = gaiaStarsAnalysis1['Speed'].value\n",
    "\n",
    "plotScatterGraphOfData(szTitle=szGraphTitle, xAxis=metallicityLabel, yAxis=alphaOnFeLabel, xData=metallicityData, yData=alphaOnFeData, xError=metallicityError, yError=alphaOnFeError, logariseXAxis=False, logariseYAxis=False, colours=colourData, colourAxisLabel=colourLabel, sizes=np.array([]))\n",
    "plt.show()\n",
    "\n",
    "print(\"The pearson's coefficient of the data is %.3f with a %.3f 2-sided p-value \" % (pearsonr(metallicityData, alphaOnFeData)[0], pearsonr(metallicityData, alphaOnFeData)[1]))\n",
    "print(\"The spearman's rank coefficient of the data is %.3f with a %.3f 2-sided p-value \" % (spearmanr(metallicityData, alphaOnFeData)[0], spearmanr(metallicityData, alphaOnFeData)[1]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
